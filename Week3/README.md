# Week 3 Materials
## Reading Research and Writing in Latex
### MONDAY
We will explore what research in machine learning looks like, how to read research papers, and read some Question Answering papers using the strategies we learn. We will also go over common evaluation metrics that show up when we are evaluating our models in NLP.

Evaluation Metrics in NLP
- Accuracy
- Precision
- Recall
- F1 Score
- Area Under the Curve (AUC)
- Mean Reciprocal Rank (MRR)
- Mean Average Precision (MAP)
- Root Mean Squared Error (RMSE)
- Bilingual Evaluation Understudy (BLEU)
- Metric for Evaluation of Translation with Explicit Ordering (METEOR)
- Recall-Oriented Understudy for Gisting Evaluation (ROUGE)

"The Most Common Evaluation Metrics in NLP" [[Article](https://towardsdatascience.com/the-most-common-evaluation-metrics-in-nlp-ced6a763ac8b)]

Reading Research
1. Read Abstract (Highlight important words/concepts)
2. Read Introduction (Highlight important words/concepts)
3. Analyze architecture/conceptual diagrams to understand paper better
4. Read the conclusion to determine the overall contribution of the paper
5. Glance through experiments to see how well their approach performed compared to other methods they list and why
6. Finally, read their approach high-level first and then in detail (with the math) on the second run


### TUESDAY
We will find papers in Question Answering and read through them in detail. We will also look at possible code implementations of 
methods proposed and have a group discussion. We will try to find an interesting application of the question answering task.

#### Areas of Question Answering
- Machine Reading Comprehension
  - English Machine Reading Comprehension Datasets: A Survey [[Paper](https://arxiv.org/pdf/2101.10421.pdf)] 
- Question Answering (given passage and a question, generate answer to question) 
  - A Neural Question Answering System for Basic Questions about Subroutines [[Paper](https://arxiv.org/pdf/2101.03999.pdf)]
  - CoQA: A Conversational Question Answering Challenge [[Paper](https://arxiv.org/pdf/1808.07042.pdf)]
  - Transformer-Based Models for Question Answering on COVID-19 [[Paper](https://arxiv.org/pdf/2101.11432.pdf)]
  - Natural Questions: a Benchmark for Question Answering Research [[Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b8c26e4347adc3453c15d96a09e6f7f102293f71.pdf)]
- Knowledge-based Question Answering
  - Knowledge Graph Question Answering using Graph-Pattern Isomorphism [[Paper](https://arxiv.org/pdf/2103.06752.pdf)]
  - A Survey on Complex Question Answering over Knowledge Base: Recent Advances and Challenges [[Paper](https://arxiv.org/pdf/2007.13069.pdf)]
  - Text-based Question Answering from Information Retrieval and Deep Neural Network Perspectives: A Survey [[Paper](https://arxiv.org/pdf/2002.06612v2.pdf)]
- Visual Question Answering (given image and a question, generate answer to question) 
  - VSQ: Visual Question Answering [[Paper](https://arxiv.org/pdf/1505.00468.pdf)]
  - Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering [[Paper](https://arxiv.org/pdf/1707.07998.pdf)]
- Open-Domain Question Answering 
  - Revisiting the Open-Domain Question Answering Pipeline [[Paper](https://arxiv.org/pdf/2009.00914.pdf)]
  - DilBert: Delaying Interaction Layers in Transformer-based Encoders for Efficient Open Domain Question Answeringn [[Paper](https://arxiv.org/pdf/2010.08422.pdf)]
  - ProQA: Resource-efficient method for pretraining a dense corpus index for open-domain QA and IR [[Paper](https://arxiv.org/pdf/2005.00038.pdf)]
  - Open Question Answering Over Tables and Text [[Paper](https://arxiv.org/pdf/2010.10439.pdf)]
  - Talk to Papers: Bringing Neural Question Answering to Academic Search [[Paper](https://arxiv.org/pdf/2004.02002.pdf)]


### WEDNESDAY
We will do activities for writing using LaTeX including:
- Setting up section headers
- IEEE double column format
- Creating tables
- Inserting images
- Citing references
- General writing procedure


### THURSDAY
We will find papers in Question Answering and read through them in detail. We will also look at possible code implementations of 
methods proposed. 

Ideas for Question Answering Paper:
- A Survey of Question Answering in Natural Language Processing
- A Comparative Study between Sequence Models and Pre-trained Language Models on Question Answering
- Apply Pre-trained Language Models on Standardized Reading Comprehension Test datasets


### FRIDAY
We will find papers in Question Answering and read through them in detail. We will also look at possible code implementations of 
methods proposed. 
